{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchdiffeq\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Define the ODE function (derivative)\n",
    "class ODEFunc(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(dim, dim)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        return self.relu(self.linear(x))\n",
    "\n",
    "# Define the ODE block that integrates the ODEFunc\n",
    "class ODEBlock(nn.Module):\n",
    "    def __init__(self, odefunc):\n",
    "        super().__init__()\n",
    "        self.odefunc = odefunc\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Integrate from t=0 to t=1\n",
    "        return torchdiffeq.odeint_adjoint(self.odefunc, x, torch.tensor([0, 1], dtype=torch.float32), method='dopri5')[1]\n",
    "\n",
    "# Define the Neural ODE model for text classification\n",
    "class ODEModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.ode_block = ODEBlock(ODEFunc(input_dim))\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ode_block(x)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "from tqdm import tqdm\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for data, target in tqdm(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    print(f'Train Epoch: {epoch} \\tAverage Loss: {sum(losses)/len(losses):.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset including all categories\n",
    "data = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Define the desired categories and their corresponding labels\n",
    "category_labels = {\n",
    "    'comp.graphics': 0,\n",
    "    'comp.os.ms-windows.misc': 0,\n",
    "    'comp.sys.ibm.pc.hardware': 0,\n",
    "    'comp.sys.mac.hardware': 0,\n",
    "    'comp.windows.x': 0,\n",
    "    'rec.autos': 1,\n",
    "    'rec.motorcycles': 1,\n",
    "    'rec.sport.baseball': 1,\n",
    "    'rec.sport.hockey': 1,\n",
    "    'sci.crypt': 2,\n",
    "    'sci.electronics': 2,\n",
    "    'sci.med': 2,\n",
    "    'sci.space': 2,\n",
    "    'talk.politics.guns': 3,\n",
    "    'talk.politics.mideast': 3,\n",
    "    'talk.politics.misc': 3,\n",
    "    'talk.religion.misc': 3\n",
    "}\n",
    "\n",
    "# Filter the dataset to include only the desired categories\n",
    "filtered_texts = []\n",
    "filtered_labels = []\n",
    "for text, label in zip(data.data, data.target):\n",
    "    category = data.target_names[label]\n",
    "    if category in category_labels:\n",
    "        filtered_texts.append(text)\n",
    "        filtered_labels.append(category_labels[category])\n",
    "\n",
    "# Now, filtered_texts contain the texts and filtered_labels contain the corresponding labels\n",
    "\n",
    "\n",
    "# Convert to TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer(max_features=100)  # Limiting to 100 features\n",
    "X = vectorizer.fit_transform(texts).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to torch.Tensor\n",
    "train_data = torch.tensor(X_train, dtype=torch.float32)\n",
    "train_labels = torch.tensor(y_train, dtype=torch.long)\n",
    "test_data = torch.tensor(X_test, dtype=torch.float32)\n",
    "test_labels = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(train_data, train_labels)\n",
    "test_dataset = TensorDataset(test_data, test_labels)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(np.unique(labels))  # Number of classes\n",
    "model = ODEModel(input_dim=input_dim, output_dim=output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train_model(model, device, train_loader, optimizer, criterion, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch_idx, (data, target) in tqdm(enumerate(train_loader)):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f'Epoch: {epoch+1}, Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "def predict_text(model, device, vectorizer, new_text, class_names):\n",
    "    model.eval()\n",
    "    processed_text = vectorizer.transform([new_text]).toarray()  # Vectorize text\n",
    "    processed_text_tensor = torch.tensor(processed_text, dtype=torch.float32).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(processed_text_tensor)\n",
    "        prediction = output.argmax(dim=1, keepdim=True)  # Get the index of the max log-probability\n",
    "    predicted_class = class_names[prediction.item()]\n",
    "    return predicted_class\n",
    "\n",
    "def evaluate_model(model, device, data_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            total_loss += criterion(output, target).item()  # Sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = 100. * correct / len(data_loader.dataset)\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/simonlee/.conda/envs/EHR-MM/lib/python3.9/site-packages/torchdiffeq/_impl/misc.py:296: UserWarning: t is not on the same device as y0. Coercing to y0.device.\n",
      "  warnings.warn(\"t is not on the same device as y0. Coercing to y0.device.\")\n",
      "236it [22:08,  5.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Average Loss: 2.6591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "236it [24:04,  6.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Average Loss: 2.5774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "236it [26:41,  6.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Average Loss: 2.5216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "236it [28:37,  7.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Average Loss: 2.4838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "236it [29:37,  7.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Average Loss: 2.4591\n",
      "Test Set Evaluation: Average loss: 2.5136, Accuracy: 20.80%\n",
      "The predicted class for the new document is: misc.forsale\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries (assuming the above code blocks are already executed)\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define criterion and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Training the model\n",
    "print(\"Starting Training\")\n",
    "train_model(model, device, train_loader, optimizer, criterion, epochs=5)\n",
    "\n",
    "# Evaluating the model on the test set\n",
    "test_loss, test_accuracy = evaluate_model(model, device, test_loader, criterion)\n",
    "print(f'Test Set Evaluation: Average loss: {test_loss:.4f}, Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "# Inference Example\n",
    "new_text = \"This is a new document to classify.\"\n",
    "class_names = data.target_names  # Assuming 'data' has been loaded with fetch_20newsgroups\n",
    "predicted_class = predict_text(model, device, vectorizer, new_text, class_names)\n",
    "print(f\"The predicted class for the new document is: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_intermediate_representations(model, data_loader, device):\n",
    "    model.eval()\n",
    "    representations = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data = data.to(device)\n",
    "            # Assuming the model has an `ode_block` attribute\n",
    "            representation = model.ode_block(data)  \n",
    "            representations.append(representation.cpu().numpy())\n",
    "            labels.append(target.cpu().numpy())\n",
    "    \n",
    "    # Concatenate all collected representations and labels\n",
    "    representations = np.concatenate(representations, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    \n",
    "    # Apply dimensionality reduction (e.g., t-SNE)\n",
    "    from sklearn.manifold import TSNE\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    reduced_data = tsne.fit_transform(representations)\n",
    "    \n",
    "    # Plot the reduced data\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for label in np.unique(labels):\n",
    "        idx = labels == label\n",
    "        plt.scatter(reduced_data[idx, 0], reduced_data[idx, 1], label=label, alpha=0.5)\n",
    "    plt.legend()\n",
    "    plt.title('t-SNE visualization of learned representations')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `func` is your ODE function modeling f(y, t)\n",
    "# and you've defined a grid of points in your 2D space\n",
    "Y, X = np.mgrid[ymin:ymax:100j, xmin:xmax:100j]\n",
    "U, V = np.zeros(Y.shape), np.zeros(X.shape)\n",
    "\n",
    "for i in range(Y.shape[0]):\n",
    "    for j in range(X.shape[1]):\n",
    "        # Evaluate the vector field at each point\n",
    "        dydt = func(None, np.array([Y[i, j], X[i, j]]))  # None for time if it's not used\n",
    "        U[i, j], V[i, j] = dydt[0], dydt[1]\n",
    "\n",
    "plt.streamplot(X, Y, U, V, color='0.8')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('EHR-MM': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "980506db2eb9913bfccf6cb29dc8680911c7506ec87df43ce6c2852551fb80c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
